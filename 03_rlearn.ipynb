{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1BD2uvaROrn"
      },
      "source": [
        "<img src='http://hilpisch.com/taim_logo.png' width=\"350px\" align=\"right\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gepzbMsSROro"
      },
      "source": [
        "# Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArwGfmVfROrp"
      },
      "source": [
        "## OpenAI Gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URFXzBUjROrp"
      },
      "source": [
        "Dr Yves J Hilpisch | The AI Machine\n",
        "\n",
        "http://aimachine.io | http://twitter.com/dyjh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_yuu-JIROrp"
      },
      "source": [
        "## CartPole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuK9gdZOROrp"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "!git clone https://github.com/tpq-classes/rl_for_finance.git\n",
        "import sys\n",
        "sys.path.append('rl_for_finance')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvirtualdisplay"
      ],
      "metadata": {
        "id": "W-oKaL3aRVpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm7t1J6AROrq"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import plt\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "from IPython import display\n",
        "plt.ion()\n",
        "plt.style.use('seaborn-v0_8')\n",
        "%matplotlib inline\n",
        "np.random.seed(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXvU42xrROrq"
      },
      "outputs": [],
      "source": [
        "env = gym.make('CartPole-v1', render_mode='rgb_array')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvt2WzAFROrr"
      },
      "outputs": [],
      "source": [
        "env.action_space.seed(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTDCpdhiROrr"
      },
      "source": [
        "## Action Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVzrRV-AROrr"
      },
      "outputs": [],
      "source": [
        "env.action_space  # type of action space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0utms9mFROrr"
      },
      "outputs": [],
      "source": [
        "env.action_space.n  # number of possible actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBIizI7rROrr"
      },
      "outputs": [],
      "source": [
        "env.action_space.sample()  # sample action | move left = 0 | move right = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v1T5x9tROrr"
      },
      "outputs": [],
      "source": [
        "env.action_space.sample()  # sample action | move left = 0 | move right = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecf0RlINROrs"
      },
      "outputs": [],
      "source": [
        "[env.action_space.sample() for _ in range(25)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R35ngTKQROrs"
      },
      "source": [
        "## Observation Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbYE0-FeROrs"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=4, suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiX3zSpEROrs"
      },
      "outputs": [],
      "source": [
        "env.observation_space  # type of observation space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmL1Mc3zROrs"
      },
      "outputs": [],
      "source": [
        "env.observation_space.high.astype(np.float16) # upper bounds for observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASRssnKnROrs"
      },
      "outputs": [],
      "source": [
        "env.observation_space.low.astype(np.float16)  # lower bounds for observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFQfKyxQROrs"
      },
      "outputs": [],
      "source": [
        "o = env.reset()\n",
        "o  # [cart position, cart velocity, pole angle, pole angular velocity]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__at_mpXROrs"
      },
      "source": [
        "## Taking Action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnNTore5ROrt"
      },
      "source": [
        "The following visualizes the effect of a number of random actions taken. See https://gist.github.com/thomelane/79e97630ba46c45985a946cae4805885"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY3Huzo7ROrt"
      },
      "outputs": [],
      "source": [
        "a = env.action_space.sample()  # random action\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwNHSVrxROrt"
      },
      "outputs": [],
      "source": [
        "r = env.step(a)  # taking action, capturing new observations\n",
        "r  # (observation, reward, done, info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekx70XjkROrt"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "img = plt.imshow(env.render()) # initialize bitmap embedding\n",
        "for e in range(201):\n",
        "    img.set_data(env.render()) # updating the data\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    a = env.action_space.sample()  # random action choice\n",
        "    obs, rew, done, _, _ = env.step(a)  # taking action\n",
        "    if done and (e + 1) < 200:\n",
        "        print('*** FAILED ***')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HANSps40ROrt"
      },
      "source": [
        "## Simple Regression Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EEUniR4ROrt"
      },
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd_SuaCKROrt"
      },
      "source": [
        "By using four weights and taking the dot product between the weights and the four observation values, the observation (state) space can be reduced from 4 dimensions to just 1. See http://kvfrans.com/simple-algoritms-for-solving-cartpole/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8myPbsKROrt"
      },
      "outputs": [],
      "source": [
        "weights = np.random.random(4) * 2 - 1  # 4 random weights ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlNc9ogmROrt"
      },
      "outputs": [],
      "source": [
        "weights  # ... between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjRxY4BmROrt"
      },
      "outputs": [],
      "source": [
        "o, _ = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjtYEmxeROru"
      },
      "outputs": [],
      "source": [
        "o  # reduction of dimensionality from 4 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlizI-uqROru"
      },
      "outputs": [],
      "source": [
        "s = np.dot(weights, o)  # ... to 1\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erp0VZDHROru"
      },
      "source": [
        "### Action Rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ibiIr90ROru"
      },
      "source": [
        "The agent behaves according to the following action rule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyqPMKunROru"
      },
      "outputs": [],
      "source": [
        "if s < 0:  # if single state value is negative ...\n",
        "    a = 0  # ... move left\n",
        "else:  # otherwise ...\n",
        "    a = 1  # ... move right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEKYZ746ROru"
      },
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpUdZQJ2ROru"
      },
      "source": [
        "### Learning Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz0-cHUNROrv"
      },
      "source": [
        "Learn those `weights` that allow the agent to survive 200 steps based on the above action rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6spLg7EiROrv"
      },
      "source": [
        "### Total Reward per Episode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnVIj2WWROrv"
      },
      "source": [
        "Function that returns the total reward `trew` given certain `weights` and the action rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8GBxr0jROrv"
      },
      "outputs": [],
      "source": [
        "def run_episode(env, weights):\n",
        "    o, _ = env.reset()\n",
        "    trew = 0\n",
        "    for _ in range(200):\n",
        "        s = np.dot(weights, o)\n",
        "        a = 0 if s < 0 else 1\n",
        "        o, rew, done, trunc, info = env.step(a)\n",
        "        trew += rew\n",
        "        if done:\n",
        "            break\n",
        "    return trew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP-x1GtXROrv"
      },
      "outputs": [],
      "source": [
        "run_episode(env, weights)  # 200 means success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_8u-F-8ROrw"
      },
      "source": [
        "### Simple Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m6XS3E5ROrw"
      },
      "source": [
        "The following code runs a maximum number of episodes `num_episodes` and stops when a certain `weights` combination makes the agent successful (200 survived actions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSLEGuuwROrw"
      },
      "outputs": [],
      "source": [
        "num_episodes = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ3DcwC5ROrw"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "bestweights = None\n",
        "besttrew = 0\n",
        "for _ in range(1, num_episodes + 1):\n",
        "    print('episode = {}'.format(_), end='\\r')\n",
        "    weights = np.random.rand(4) * 2 - 1\n",
        "    trew = run_episode(env, weights)\n",
        "    if trew > besttrew:\n",
        "        besttrew = trew\n",
        "        bestweights = weights\n",
        "        if trew == 200:  # success?\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gFCUhLQROrw"
      },
      "outputs": [],
      "source": [
        "weights  # learned ('optimal') weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9NbAzC-ROrw"
      },
      "source": [
        "### Testing the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThE4rr8-ROrw"
      },
      "outputs": [],
      "source": [
        "# some episodes with the learned weights\n",
        "res = []\n",
        "for _ in range(15):\n",
        "    trew = run_episode(env, weights)\n",
        "    res.append(int(trew))\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLr2diTlROrw"
      },
      "outputs": [],
      "source": [
        "# a single episode visualized (inline)\n",
        "o, _ = env.reset()\n",
        "img = plt.imshow(env.render()) # initialize bitmap embedding\n",
        "for _ in range(200):\n",
        "    img.set_data(env.render()) # updating the data\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    s = np.dot(weights, o)\n",
        "    a = 0 if s < 0 else 1\n",
        "    o, rew, done, itrunc, info = env.step(a)  # taking action\n",
        "    if done and (_ + 1) < 200:\n",
        "        print('*** FAILED at STEP {} ***'.format(_ + 1))\n",
        "        break\n",
        "if not done:\n",
        "    print('*** SUCCESS ***')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTzbHbIjROrx"
      },
      "outputs": [],
      "source": [
        "# a single episode visualized (pop-up)\n",
        "o, _ = env.reset()\n",
        "for _ in range(1, 200 + 1):\n",
        "    env.render()\n",
        "    s = np.dot(weights, o)\n",
        "    a = 0 if s < 0 else 1\n",
        "    o, rew, done, trunc,  info = env.step(a)  # taking action\n",
        "    print('{:3d} | state={:6.3f} | action={}'.format(_, s, a), end='\\r')\n",
        "    if done:\n",
        "        if _ < 200:\n",
        "            print('\\n*** FAILED at STEP {} ***'.format(_ + 1))\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xVaNaDlROrx"
      },
      "source": [
        "<img src='http://hilpisch.com/taim_logo.png' width=\"350px\" align=\"right\">\n",
        "\n",
        "<br><br><br><a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:ai@tpq.io\">ai@tpq.io</a>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}