{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGhaJrb74D3N"
      },
      "source": [
        "<img src='http://hilpisch.com/taim_logo.png' width=\"350px\" align=\"right\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7jpwMWo4D3P"
      },
      "source": [
        "# Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40hRu_w94D3Q"
      },
      "source": [
        "## OpenAI Gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwj8n3IK4D3S"
      },
      "source": [
        "Dr Yves J Hilpisch | The AI Machine\n",
        "\n",
        "http://aimachine.io | http://twitter.com/dyjh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuqwvhbh4D3U"
      },
      "source": [
        "## CartPole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4H91Bqa4D3V"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "!git clone https://github.com/tpq-classes/rl_for_finance.git\n",
        "import sys\n",
        "sys.path.append('rl_for_finance')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvirtualdisplay\n"
      ],
      "metadata": {
        "id": "Qk_TgRle42Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xJnFizj4D3W"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import plt\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "from IPython import display\n",
        "plt.ion()\n",
        "plt.style.use('seaborn-v0_8')\n",
        "%matplotlib inline\n",
        "np.random.seed(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2x0E3iJ4D3X"
      },
      "outputs": [],
      "source": [
        "env = gym.make('CartPole-v1', render_mode='rgb_array')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsU-GhP14D3X"
      },
      "outputs": [],
      "source": [
        "env.action_space.seed(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzREq_JD4D3Y"
      },
      "source": [
        "## Action Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8i4zv9o4D3Y"
      },
      "outputs": [],
      "source": [
        "env.action_space  # type of action space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfgOnkyv4D3Z"
      },
      "outputs": [],
      "source": [
        "env.action_space.n  # number of possible actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3psoQ4Bj4D3Z"
      },
      "outputs": [],
      "source": [
        "env.action_space.sample()  # sample action | move left = 0 | move right = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3tQJL9s4D3Z"
      },
      "outputs": [],
      "source": [
        "env.action_space.sample()  # sample action | move left = 0 | move right = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVyDn2Db4D3a"
      },
      "outputs": [],
      "source": [
        "[env.action_space.sample() for _ in range(25)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdRLAppB4D3a"
      },
      "source": [
        "## Observation Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37rTg19U4D3a"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=4, suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG26m3eP4D3a"
      },
      "outputs": [],
      "source": [
        "env.observation_space  # type of observation space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XxDMMwZ4D3b"
      },
      "outputs": [],
      "source": [
        "env.observation_space.high.astype(np.float16) # upper bounds for observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxZDWQIK4D3b"
      },
      "outputs": [],
      "source": [
        "env.observation_space.low.astype(np.float16)  # lower bounds for observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPpJbhjl4D3b"
      },
      "outputs": [],
      "source": [
        "o = env.reset()\n",
        "o  # [cart position, cart velocity, pole angle, pole angular velocity]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Z8klVx4D3c"
      },
      "source": [
        "## Taking Action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vatSv6O4D3c"
      },
      "source": [
        "The following visualizes the effect of a number of random actions taken. See https://gist.github.com/thomelane/79e97630ba46c45985a946cae4805885"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bdOrLlw4D3c"
      },
      "outputs": [],
      "source": [
        "a = env.action_space.sample()  # random action\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-wgoVYN4D3c"
      },
      "outputs": [],
      "source": [
        "r = env.step(a)  # taking action, capturing new observations\n",
        "r  # (observation, reward, done, info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6SGGm5g4D3d"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "img = plt.imshow(env.render()) # initialize bitmap embedding\n",
        "for e in range(201):\n",
        "    img.set_data(env.render()) # updating the data\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    a = env.action_space.sample()  # random action choice\n",
        "    obs, rew, done, _, _ = env.step(a)  # taking action\n",
        "    if done and (e + 1) < 200:\n",
        "        print('*** FAILED ***')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH_Dr0sD4D3d"
      },
      "source": [
        "## Simple Regression Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-So8c_SI4D3d"
      },
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3umExebW4D3d"
      },
      "source": [
        "By using four weights and taking the dot product between the weights and the four observation values, the observation (state) space can be reduced from 4 dimensions to just 1. See http://kvfrans.com/simple-algoritms-for-solving-cartpole/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4puOn00c4D3e"
      },
      "outputs": [],
      "source": [
        "weights = np.random.random(4) * 2 - 1  # 4 random weights ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okmofY8-4D3e"
      },
      "outputs": [],
      "source": [
        "weights  # ... between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM6ETdTK4D3e"
      },
      "outputs": [],
      "source": [
        "o, _ = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOJYR8Xl4D3e"
      },
      "outputs": [],
      "source": [
        "o  # reduction of dimensionality from 4 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF5I2yW54D3f"
      },
      "outputs": [],
      "source": [
        "s = np.dot(weights, o)  # ... to 1\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFdX-5yM4D3f"
      },
      "source": [
        "### Action Rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPl3s6-X4D3f"
      },
      "source": [
        "The agent behaves according to the following action rule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nVG-jkz4D3f"
      },
      "outputs": [],
      "source": [
        "if s < 0:  # if single state value is negative ...\n",
        "    a = 0  # ... move left\n",
        "else:  # otherwise ...\n",
        "    a = 1  # ... move right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFW6HQA64D3f"
      },
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vlSPiFL4D3g"
      },
      "source": [
        "### Learning Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaspfojO4D3g"
      },
      "source": [
        "Learn those `weights` that allow the agent to survive 200 steps based on the above action rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97FekFQq4D3g"
      },
      "source": [
        "### Total Reward per Episode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkYlnUDZ4D3g"
      },
      "source": [
        "Function that returns the total reward `trew` given certain `weights` and the action rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC09d17F4D3g"
      },
      "outputs": [],
      "source": [
        "def run_episode(env, weights):\n",
        "    o, _ = env.reset()\n",
        "    trew = 0\n",
        "    for _ in range(200):\n",
        "        s = np.dot(weights, o)\n",
        "        a = 0 if s < 0 else 1\n",
        "        o, rew, done, trunc, info = env.step(a)\n",
        "        trew += rew\n",
        "        if done:\n",
        "            break\n",
        "    return trew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq4gBZb94D3h"
      },
      "outputs": [],
      "source": [
        "run_episode(env, weights)  # 200 means success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9r6TRTo4D3h"
      },
      "source": [
        "### Simple Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHgXsJj-4D3h"
      },
      "source": [
        "The following code runs a maximum number of episodes `num_episodes` and stops when a certain `weights` combination makes the agent successful (200 survived actions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvzcPJ3w4D3h"
      },
      "outputs": [],
      "source": [
        "num_episodes = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNfgrxgA4D3i"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "bestweights = None\n",
        "besttrew = 0\n",
        "for _ in range(1, num_episodes + 1):\n",
        "    print('episode = {}'.format(_), end='\\r')\n",
        "    weights = np.random.rand(4) * 2 - 1\n",
        "    trew = run_episode(env, weights)\n",
        "    if trew > besttrew:\n",
        "        besttrew = trew\n",
        "        bestweights = weights\n",
        "        if trew == 200:  # success?\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6ZvvT_44D3i"
      },
      "outputs": [],
      "source": [
        "weights  # learned ('optimal') weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dv71hbM4D3i"
      },
      "source": [
        "### Testing the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfdZVlFL4D3i"
      },
      "outputs": [],
      "source": [
        "# some episodes with the learned weights\n",
        "res = []\n",
        "for _ in range(15):\n",
        "    trew = run_episode(env, weights)\n",
        "    res.append(int(trew))\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh4KP5qY4D3i"
      },
      "outputs": [],
      "source": [
        "# a single episode visualized (inline)\n",
        "o, _ = env.reset()\n",
        "img = plt.imshow(env.render()) # initialize bitmap embedding\n",
        "for _ in range(200):\n",
        "    img.set_data(env.render()) # updating the data\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    s = np.dot(weights, o)\n",
        "    a = 0 if s < 0 else 1\n",
        "    o, rew, done, itrunc, info = env.step(a)  # taking action\n",
        "    if done and (_ + 1) < 200:\n",
        "        print('*** FAILED at STEP {} ***'.format(_ + 1))\n",
        "        break\n",
        "if not done:\n",
        "    print('*** SUCCESS ***')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwcbj8gW4D3i"
      },
      "outputs": [],
      "source": [
        "# a single episode visualized (pop-up)\n",
        "o, _ = env.reset()\n",
        "for _ in range(1, 200 + 1):\n",
        "    env.render()\n",
        "    s = np.dot(weights, o)\n",
        "    a = 0 if s < 0 else 1\n",
        "    o, rew, done, trunc,  info = env.step(a)  # taking action\n",
        "    print('{:3d} | state={:6.3f} | action={}'.format(_, s, a), end='\\r')\n",
        "    if done:\n",
        "        if _ < 200:\n",
        "            print('\\n*** FAILED at STEP {} ***'.format(_ + 1))\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2YyJL-x4D3i"
      },
      "source": [
        "<img src='http://hilpisch.com/taim_logo.png' width=\"350px\" align=\"right\">\n",
        "\n",
        "<br><br><br><a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:ai@tpq.io\">ai@tpq.io</a>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}